# Threat Model

Gabriel aims to act as a privacy-first assistant that helps users maintain situational awareness about their digital security. The initial focus is on local execution with optional encrypted inference through [token.place](https://github.com/futuroptimist/token.place).

## Security Assumptions

- Users operate Gabriel on hardware they control.
- Network connectivity is optional and should be minimized.
- Secrets such as API keys should be stored in environment variables or encrypted files, never committed to source control.
- Logs must avoid collecting personally identifiable information (PII) by default.

## Attack Surface

- Compromise of the local machine running Gabriel.
- Leakage of secrets through misconfigured logging or unencrypted storage.
- Exposure when calling external APIs if not using an encrypted channel.
- Malicious or buggy pull requests generated by automated agents.
- Metadata leaks from cross-repository scanning tools.
- Prompt injection via hidden instructions in repository code, documentation, or dependencies.

## Mitigations

- Encourage filesystem encryption and strong access controls.
- Include examples of secure key storage using tools like `keyring` or OS keychains.
- Limit logs to debug-level messages and strip sensitive data before writing.
- Prefer offline models or encrypted inference when possible.
- Use pre-commit hooks and CI checks to block risky automated changes.
- Restrict cross-repo crawl tokens to read-only scope and sanitize output.
- Treat third-party code and docs as untrusted and review for hidden prompts or commands.
- Employ the `gabriel.ingestion.text` scanner (pre-commit hook) to detect zero-width characters or other concealed text.
- Grant automated agents least privilege and require human review before executing their suggestions.
